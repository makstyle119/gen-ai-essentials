{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple Sentence similarity example using SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "# 1. Load a pretrained CrossEncoder model\n",
    "model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")\n",
    "\n",
    "# We want to compute the similarity between the query sentence...\n",
    "query = \"A man is eating pasta.\"\n",
    "\n",
    "# ... and all sentences in the corpus\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "# 2. We rank all sentences in the corpus for the query\n",
    "ranks = model.rank(query, corpus)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Query: \", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{corpus[rank['corpus_id']]}\")\n",
    "\"\"\"\n",
    "Query:  A man is eating pasta.\n",
    "0.67    A man is eating food.\n",
    "0.34    A man is eating a piece of bread.\n",
    "0.08    A man is riding a horse.\n",
    "0.07    A man is riding a white horse on an enclosed ground.\n",
    "0.01    The girl is carrying a baby.\n",
    "0.01    Two men pushed carts through the woods.\n",
    "0.01    A monkey is playing drums.\n",
    "0.01    A woman is playing violin.\n",
    "0.01    A cheetah is running behind its prey.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Alternatively, you can also manually compute the score between two sentences\n",
    "import numpy as np\n",
    "\n",
    "sentence_combinations = [[query, sentence] for sentence in corpus]\n",
    "scores = model.predict(sentence_combinations)\n",
    "\n",
    "# Sort the scores in decreasing order to get the corpus indices\n",
    "ranked_indices = np.argsort(scores)[::-1]\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Indices:\", ranked_indices)\n",
    "\"\"\"\n",
    "Scores: [0.6732372, 0.34102544, 0.00542465, 0.07569341, 0.00525378, 0.00536814, 0.06676237, 0.00534825, 0.00516717]\n",
    "Indices: [0 1 3 6 2 5 7 4 8]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
